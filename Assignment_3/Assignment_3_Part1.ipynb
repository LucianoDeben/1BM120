{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "Install the necessary libraries, including Gymnasium, Stable Baselines3, and SB3 Contrib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy as evaluate_policy_maskable\n",
    "\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Import BoundedKnapsack Environment\n",
    "from knapsack_env import BoundedKnapsackEnv\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "seed = 2024\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "TIME_STEPS = 1000000\n",
    "EVAL_EPISODES = 100   \n",
    "EVAL_FREQ = int(TIME_STEPS**0.5)     \n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Instance of the Environment\n",
    "Create an instance of the BoundedKnapsack environment with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Space: (array([[ 82,  65,  60,  69,  35,  87,  35,  48,  40,  23,  15,  86,   3,\n",
      "         41,  26,  64,  42,  52,  95,  67,  17,  45,  93,  30,  53,  50,\n",
      "         20,  74,  49,  66,   5,  48,  51,  19,  71,  51,  10,  93,  44,\n",
      "         55,  28,  93,  31,  37,  88,  30,   6,   3,   9,   9,  37,  15,\n",
      "         38,  83,  39,  26,  33,  98,  69,  82,  25,  90,  18,  57,  95,\n",
      "         95,  60,  65,  38,  86,  57,  80,  75,  70,  10,  19,  20,  66,\n",
      "         57,  42,  36,  30,  63,  35,  22,  34,  59,  80,  48,  56,  70,\n",
      "         55,  20,  21,  83,  57,  43,  66,  71,  79,   3,  99,   7,  54,\n",
      "         58,  79,  69,  43,  40,   6,  34,  73,  15,  19,  32,  82,  31,\n",
      "          9,   2,  31,  54,  83,  68,  44,  59,  41,  63,  28,  95,  48,\n",
      "         36,  98,  91,  71,  39,  31,  60,  11,  33,  10,  94,  93,  30,\n",
      "         36,  34,  20,  99,  80,  85,  89,  49,  79,  85,  76,   3,  50,\n",
      "         63,  11,  83,  40,  23,  68,  29,  55,  43,  12,  28,  21,  52,\n",
      "         52,  44,  45,  46,  93,  24,  26,  26,  17,  59,  62,  98,  71,\n",
      "         30,  21,  76,  46,  80,   9,  69,  93,  95,  15,  68,  36,  86,\n",
      "         43,  66,  64,  66,  10, 200],\n",
      "       [ 89,  97,  29,  59,  83,  95,   2,   6,  33,  55,  75,  36,   5,\n",
      "          9,  75,  25,  40,  94,  71,  15,  21,  77,   7,  61,  81,  93,\n",
      "         85,  30,  47,  14,  85,  18,  27,  92,   8,  54,  63,  37,  67,\n",
      "         98,  37,  86,  30,   3,  50,  55,  80,  36,  74,  53,   3,  31,\n",
      "         28,  40,  64,  44,  41,  61,  96,  38,  75,  15,  21,  59,  16,\n",
      "         94,  94,  34,  86,  30,  79,  78,  45,  97,  88,  70,  19,  36,\n",
      "          5,  24,  42,  52,  64,  63,  85,  11,  72,  73,  10,  82,  15,\n",
      "          0,  90,  73,  21,   4,  24,  96,  23,  86,  38,   6,  69,  43,\n",
      "         44,  43,  49,  57,  98,  79,  54,  78,  57,   2,  83,  93,  76,\n",
      "         27,  85,  26,  92,  52,  28,  58,  76,  31,  66,  66,  83,  83,\n",
      "         54,  44,  72,  72,  76,  48,  42,  53,  84,  58,  23,  45,  17,\n",
      "         37,   5,  58,  19,  92,  86,  90,  23,  73,   9,  13,   0,  79,\n",
      "         61,  62,  91,  24,  14,  97,  81,  94,  73,  54,  54,   4,  86,\n",
      "         80,  71,  60,  90,  62,  51,  96,  49,  63,  87,  90,  90,  17,\n",
      "          8,  28,  69,   9,  72,  31,  72,  34,   6,  52,  49,  50,  42,\n",
      "         35,  82,  40,   5,   8,   0],\n",
      "       [  5,   8,   3,   5,   3,   6,   6,   1,   9,   9,   2,   9,   8,\n",
      "          2,   5,   9,   1,   3,   3,   4,   4,   1,   4,   2,   7,   7,\n",
      "          5,   2,   9,   3,   4,   2,   4,   6,   2,   8,   5,   3,   3,\n",
      "          1,   3,   4,   1,   9,   4,   3,   3,   5,   5,   4,   3,   9,\n",
      "          9,   5,   3,   7,   7,   7,   2,   3,   9,   1,   3,   5,   8,\n",
      "          5,   1,   8,   6,   8,   5,   1,   4,   4,   1,   5,   5,   5,\n",
      "          3,   1,   7,   9,   8,   4,   7,   5,   6,   3,   2,   1,   3,\n",
      "          3,   8,   2,   9,   6,   2,   6,   1,   9,   4,   5,   1,   4,\n",
      "          4,   1,   2,   8,   1,   5,   9,   3,   5,   2,   1,   2,   2,\n",
      "          9,   3,   6,   1,   1,   3,   8,   1,   8,   5,   3,   5,   7,\n",
      "          1,   6,   3,   2,   3,   8,   5,   9,   7,   1,   6,   6,   6,\n",
      "          3,   3,   4,   4,   8,   2,   3,   4,   6,   3,   3,   8,   1,\n",
      "          5,   3,   6,   6,   6,   5,   2,   4,   5,   9,   5,   8,   2,\n",
      "          6,   6,   8,   8,   7,   9,   6,   4,   4,   5,   4,   2,   7,\n",
      "          9,   8,   3,   8,   8,   6,   3,   4,   9,   4,   9,   1,   6,\n",
      "          3,   1,   8,   9,   7,   0]]), {})\n",
      "Action Space Size: 200\n"
     ]
    }
   ],
   "source": [
    "# Enable the environment\n",
    "env = BoundedKnapsackEnv(n_items=200, max_weight=200)\n",
    "\n",
    "# Create evaluation environment\n",
    "eval_env = Monitor(env)\n",
    "\n",
    "# Inspect the state space and action spaces\n",
    "state_space = env.reset()\n",
    "action_space_size = env.action_space.n\n",
    "\n",
    "# Print the state space and action space size\n",
    "print(f\"State Space: {state_space}\")\n",
    "print(f\"Action Space Size: {action_space_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test DRL Agents\n",
    "Train and test at least two different DRL agents using the algorithms provided in Stable Baselines3 with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent: 395.0 +/- 0.0\n",
      "Mean reward for DQN agent: 430.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.Tanh, net_arch=[64, 64])\n",
    "\n",
    "# Create a log directory\n",
    "log_dir = './logs/'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.Tanh, net_arch=[64, 64])\n",
    "\n",
    "# Training the PPO agent\n",
    "ppo_model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'ppo_small/')\n",
    "ppo_model.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Training the DQN agent\n",
    "dqn_model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=VERBOSE,\n",
    "    tensorboard_log=log_dir + \"dqn_small/\",\n",
    ")\n",
    "dqn_model.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agent\n",
    "mean_reward_ppo, std_reward_ppo = evaluate_policy(ppo_model, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for PPO agent: {mean_reward_ppo} +/- {std_reward_ppo}\")\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward_dqn, std_reward_dqn = evaluate_policy(dqn_model, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for DQN agent: {mean_reward_dqn} +/- {std_reward_dqn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Different Neural Network Architectures\n",
    "Experiment with different neural network architectures for the DRL agents with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent: 279.0 +/- 0.0\n",
      "Mean reward for DQN agent: 340.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[128, 128])\n",
    "\n",
    "# Training the PPO agent\n",
    "ppo_model_large = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'ppo_large/')\n",
    "ppo_model_large.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Training the DQN agent\n",
    "dqn_model_large = DQN(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'dqn_large/')\n",
    "dqn_model_large.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agentP\n",
    "mean_reward, std_reward = evaluate_policy(ppo_model_large, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "print(f\"Mean reward for PPO agent: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward, std_reward = evaluate_policy(dqn_model_large, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "print(f\"Mean reward for DQN agent: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the Algorithms Hyperparameters\n",
    "Tune the hyperparameters of the algorithms by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent after hyperparameter tuning: 340.0 +/- 0.0\n",
      "Mean reward for DQN agent after hyperparameter tuning: 340.0 +/- 0.0\n",
      "Mean reward for A2C agent after hyperparameter tuning: 340.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[128, 128])\n",
    "\n",
    "# Tuning the hyperparameters of the PPO agent\n",
    "ppo_model_tuned = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, learning_rate=0.0003, n_steps=2048,\n",
    "                      batch_size=64, n_epochs=10, gamma=0.99, gae_lambda=0.95, clip_range=0.2, tensorboard_log=log_dir + 'ppo_tuned/')\n",
    "ppo_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agent\n",
    "mean_reward_ppo, std_reward_ppo = evaluate_policy(ppo_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for PPO agent after hyperparameter tuning: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# Tuning the hyperparameters of the DQN agent\n",
    "dqn_model_tuned = DQN(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, learning_rate=0.0005, buffer_size=10000, learning_starts=1000,\n",
    "                      batch_size=64, exploration_initial_eps=0.99, exploration_final_eps=0.02 , tau=1.0, gamma=0.99, train_freq=4, gradient_steps=1, tensorboard_log=log_dir + 'dqn_tuned/')\n",
    "dqn_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward_dqn, std_reward_dqn = evaluate_policy(dqn_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for DQN agent after hyperparameter tuning: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# Tuning the hyperparameters of the A2C agent\n",
    "a2c_model_tuned = A2C(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, learning_rate=0.0007, n_steps=5,\n",
    "                      gamma=0.99, gae_lambda=1.0, ent_coef=0.0, vf_coef=0.5, max_grad_norm=0.5, use_rms_prop=False, use_sde=False, tensorboard_log=log_dir + 'a2c_tuned/')\n",
    "a2c_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the A2C agent\n",
    "mean_reward_a2c, std_reward_a2c = evaluate_policy(a2c_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for A2C agent after hyperparameter tuning: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Agents and Compare Results\n",
    "Evaluate the performance of the agents and compare the best results obtained using the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the agents and their corresponding mean rewards and standard deviations\n",
    "agents = ['PPO', 'DQN', 'A2C']\n",
    "mean_rewards = [mean_reward_ppo, mean_reward_dqn, mean_reward_a2c]\n",
    "std_rewards = [std_reward_ppo, std_reward_dqn, std_reward_a2c]\n",
    "\n",
    "# Plotting the mean rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(agents, mean_rewards, yerr=std_rewards, align='center', alpha=0.7, ecolor='black', capsize=10)\n",
    "plt.ylabel('Mean Reward')\n",
    "plt.title('Comparison of Mean Rewards of Different Agents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is PPO with a mean reward of 552.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:284: UserWarning: Path 'models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "# Define the agents and their corresponding mean rewards, standard deviations, and models\n",
    "agents = ['PPO', 'DQN', 'A2C']\n",
    "mean_rewards = [mean_reward_ppo, mean_reward_dqn, mean_reward_a2c]\n",
    "models = [ppo_model_tuned, dqn_model_tuned, a2c_model_tuned]\n",
    "\n",
    "# Save all the 3 tuned models using list comprehension\n",
    "[model.save(name) for model, name in zip(models, [\"models/ppo_tuned\", \"models/dqn_tuned\", \"models/a2c_tuned\"])]\n",
    "\n",
    "# Determine the index of the best model\n",
    "best_index = np.argmax(mean_rewards)\n",
    "\n",
    "print(f\"The best model is {agents[best_index]} with a mean reward of {mean_rewards[best_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2\n",
    "\n",
    "---\n",
    "\n",
    "## Enabling action masking, train and test a MaskablePPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 3190.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a function for the mask\n",
    "def mask_fn(env):\n",
    "    return env.get_mask()\n",
    "\n",
    "# Create an instance of the environment with mask enabled\n",
    "env = BoundedKnapsackEnv(n_items=200, max_weight=200, mask=True)\n",
    "\n",
    "# Wrap the environment with the ActionMasker\n",
    "vec_env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Create an evaluation environment\n",
    "eval_vec_env = Monitor(vec_env)\n",
    "\n",
    "# Define the policy architecture\n",
    "policy_kwargs = dict(\n",
    "    net_arch=dict(pi=[128, 128, 128], vf=[128, 128, 128]),  \n",
    ")\n",
    "\n",
    "# Train a MaskablePPO agent\n",
    "model = MaskablePPO(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=VERBOSE,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    learning_rate=3e-4,\n",
    "    tensorboard_log=log_dir + 'maskable_ppo/'\n",
    ")\n",
    "\n",
    "# Adjust timesteps for meaningful training\n",
    "model.learn(total_timesteps=TIME_STEPS, use_masking=True)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy_maskable(model, eval_vec_env, n_eval_episodes=EVAL_EPISODES, use_masking=True)\n",
    "\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with different neural network architectures and tune the algorithm hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: {'pi': [64, 64], 'vf': [64, 64]}, Learning Rate: 0.0003, Mean reward: 3190.0 +/- 0.0\n",
      "New best mean reward: 3738.0 +/- 0.0, model saved.\n",
      "Architecture: {'pi': [256, 256], 'vf': [256, 256]}, Learning Rate: 0.001, Mean reward: 3190.0 +/- 0.0\n",
      "Architecture: {'pi': [128, 128], 'vf': [128, 128]}, Learning Rate: 0.0001, Mean reward: 3190.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a list of configurations to experiment with\n",
    "configurations = [\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[64, 64], vf=[64, 64])),\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"n_steps\": 2048,\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"gamma\": 0.99,\n",
    "    },\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[256, 256], vf=[256, 256])),\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"n_steps\": 1024,\n",
    "        \"ent_coef\": 0.01,\n",
    "        \"gamma\": 0.97,\n",
    "    },\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[128, 128], vf=[128, 128])),\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"n_steps\": 4096,\n",
    "        \"ent_coef\": 0.02,\n",
    "        \"gamma\": 0.95,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Initialize best mean reward to negative infinity\n",
    "best_mean_reward = -np.inf\n",
    "\n",
    "# Loop over the architectures and learning rates\n",
    "for config in configurations:\n",
    "    policy_kwargs = config[\"policy_kwargs\"]\n",
    "    model = MaskablePPO(\n",
    "        \"MlpPolicy\",\n",
    "        vec_env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=VERBOSE,\n",
    "        n_steps=config[\"n_steps\"],\n",
    "        batch_size=64,\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        ent_coef=config[\"ent_coef\"],\n",
    "        gamma=config[\"gamma\"],\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        target_kl=None,\n",
    "        tensorboard_log=log_dir + 'maskable_ppo/',\n",
    "    )\n",
    "    model.learn(total_timesteps=TIME_STEPS, use_masking=True)\n",
    "    mean_reward_mppo, std_reward_mppo = evaluate_policy_maskable(model, eval_vec_env, n_eval_episodes=EVAL_EPISODES, use_masking=True)\n",
    "    print(f\"Architecture: {config['policy_kwargs']['net_arch']}, Learning Rate: {config['learning_rate']}, Mean reward: {mean_reward} +/- {std_reward}\")    \n",
    "    # If this mean reward is greater than the current best, save this model\n",
    "    if mean_reward_mppo > best_mean_reward:\n",
    "        best_mean_reward = mean_reward_mppo\n",
    "        model.save(\"models/mppo_best\")\n",
    "        print(f\"New best mean reward: {mean_reward_mppo} +/- {std_reward_mppo}, model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the agent and compare the best results obtained with those of the best agent from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 - Mean reward: 552.0 +/- 0.0\n",
      "Part 2 - Mean reward: 3738.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from Part 1\n",
    "if agents[best_index] == 'PPO':\n",
    "    best_model_part1 = PPO.load(\"models/ppo_tuned\", env=env)\n",
    "elif agents[best_index] == 'DQN':\n",
    "    best_model_part1 = DQN.load(\"models/dqn_tuned\", env=env)\n",
    "elif agents[best_index] == 'A2C':\n",
    "    best_model_part1 = A2C.load(\"models/a2c_tuned\", env=env)\n",
    "else:\n",
    "    print(\"Unknown model type\")\n",
    "\n",
    "# Load the best model from Part 2\n",
    "best_model_part2 = MaskablePPO.load(\"models/mppo_best\", env=env)\n",
    "\n",
    "# Evaluate the best model from Part 1\n",
    "mean_reward_part1, std_reward_part1 = evaluate_policy(best_model_part1, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "# Evaluate the best model from Part 2\n",
    "mean_reward_part2, std_reward_part2 = evaluate_policy_maskable(best_model_part2, eval_vec_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Part 1 - Mean reward: {mean_reward_part1} +/- {std_reward_part1}\")\n",
    "print(f\"Part 2 - Mean reward: {mean_reward_part2} +/- {std_reward_part2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
