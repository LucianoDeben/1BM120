{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "Install the necessary libraries, including Gymnasium, Stable Baselines3, and SB3 Contrib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Importing required modules\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy as evaluate_policy_maskable\n",
    "\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Import BoundedKnapsack Environment\n",
    "from knapsack_env import BoundedKnapsackEnv\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "seed = 2024\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "TIME_STEPS = 10000\n",
    "EVAL_EPISODES = 100   \n",
    "EVAL_FREQ = int(TIME_STEPS**0.5)     \n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Instance of the Environment\n",
    "Create an instance of the BoundedKnapsack environment with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Space: (array([[ 82,  65,  60,  69,  35,  87,  35,  48,  40,  23,  15,  86,   3,\n",
      "         41,  26,  64,  42,  52,  95,  67,  17,  45,  93,  30,  53,  50,\n",
      "         20,  74,  49,  66,   5,  48,  51,  19,  71,  51,  10,  93,  44,\n",
      "         55,  28,  93,  31,  37,  88,  30,   6,   3,   9,   9,  37,  15,\n",
      "         38,  83,  39,  26,  33,  98,  69,  82,  25,  90,  18,  57,  95,\n",
      "         95,  60,  65,  38,  86,  57,  80,  75,  70,  10,  19,  20,  66,\n",
      "         57,  42,  36,  30,  63,  35,  22,  34,  59,  80,  48,  56,  70,\n",
      "         55,  20,  21,  83,  57,  43,  66,  71,  79,   3,  99,   7,  54,\n",
      "         58,  79,  69,  43,  40,   6,  34,  73,  15,  19,  32,  82,  31,\n",
      "          9,   2,  31,  54,  83,  68,  44,  59,  41,  63,  28,  95,  48,\n",
      "         36,  98,  91,  71,  39,  31,  60,  11,  33,  10,  94,  93,  30,\n",
      "         36,  34,  20,  99,  80,  85,  89,  49,  79,  85,  76,   3,  50,\n",
      "         63,  11,  83,  40,  23,  68,  29,  55,  43,  12,  28,  21,  52,\n",
      "         52,  44,  45,  46,  93,  24,  26,  26,  17,  59,  62,  98,  71,\n",
      "         30,  21,  76,  46,  80,   9,  69,  93,  95,  15,  68,  36,  86,\n",
      "         43,  66,  64,  66,  10, 200],\n",
      "       [ 89,  97,  29,  59,  83,  95,   2,   6,  33,  55,  75,  36,   5,\n",
      "          9,  75,  25,  40,  94,  71,  15,  21,  77,   7,  61,  81,  93,\n",
      "         85,  30,  47,  14,  85,  18,  27,  92,   8,  54,  63,  37,  67,\n",
      "         98,  37,  86,  30,   3,  50,  55,  80,  36,  74,  53,   3,  31,\n",
      "         28,  40,  64,  44,  41,  61,  96,  38,  75,  15,  21,  59,  16,\n",
      "         94,  94,  34,  86,  30,  79,  78,  45,  97,  88,  70,  19,  36,\n",
      "          5,  24,  42,  52,  64,  63,  85,  11,  72,  73,  10,  82,  15,\n",
      "          0,  90,  73,  21,   4,  24,  96,  23,  86,  38,   6,  69,  43,\n",
      "         44,  43,  49,  57,  98,  79,  54,  78,  57,   2,  83,  93,  76,\n",
      "         27,  85,  26,  92,  52,  28,  58,  76,  31,  66,  66,  83,  83,\n",
      "         54,  44,  72,  72,  76,  48,  42,  53,  84,  58,  23,  45,  17,\n",
      "         37,   5,  58,  19,  92,  86,  90,  23,  73,   9,  13,   0,  79,\n",
      "         61,  62,  91,  24,  14,  97,  81,  94,  73,  54,  54,   4,  86,\n",
      "         80,  71,  60,  90,  62,  51,  96,  49,  63,  87,  90,  90,  17,\n",
      "          8,  28,  69,   9,  72,  31,  72,  34,   6,  52,  49,  50,  42,\n",
      "         35,  82,  40,   5,   8,   0],\n",
      "       [  5,   8,   3,   5,   3,   6,   6,   1,   9,   9,   2,   9,   8,\n",
      "          2,   5,   9,   1,   3,   3,   4,   4,   1,   4,   2,   7,   7,\n",
      "          5,   2,   9,   3,   4,   2,   4,   6,   2,   8,   5,   3,   3,\n",
      "          1,   3,   4,   1,   9,   4,   3,   3,   5,   5,   4,   3,   9,\n",
      "          9,   5,   3,   7,   7,   7,   2,   3,   9,   1,   3,   5,   8,\n",
      "          5,   1,   8,   6,   8,   5,   1,   4,   4,   1,   5,   5,   5,\n",
      "          3,   1,   7,   9,   8,   4,   7,   5,   6,   3,   2,   1,   3,\n",
      "          3,   8,   2,   9,   6,   2,   6,   1,   9,   4,   5,   1,   4,\n",
      "          4,   1,   2,   8,   1,   5,   9,   3,   5,   2,   1,   2,   2,\n",
      "          9,   3,   6,   1,   1,   3,   8,   1,   8,   5,   3,   5,   7,\n",
      "          1,   6,   3,   2,   3,   8,   5,   9,   7,   1,   6,   6,   6,\n",
      "          3,   3,   4,   4,   8,   2,   3,   4,   6,   3,   3,   8,   1,\n",
      "          5,   3,   6,   6,   6,   5,   2,   4,   5,   9,   5,   8,   2,\n",
      "          6,   6,   8,   8,   7,   9,   6,   4,   4,   5,   4,   2,   7,\n",
      "          9,   8,   3,   8,   8,   6,   3,   4,   9,   4,   9,   1,   6,\n",
      "          3,   1,   8,   9,   7,   0]]), {})\n",
      "Action Space Size: 200\n"
     ]
    }
   ],
   "source": [
    "# Enable the environment\n",
    "env = BoundedKnapsackEnv(n_items=200, max_weight=200)\n",
    "\n",
    "# Create evaluation environment\n",
    "eval_env = Monitor(env)\n",
    "\n",
    "# Inspect the state space and action spaces\n",
    "state_space = env.reset()\n",
    "action_space_size = env.action_space.n\n",
    "\n",
    "# Print the state space and action space size\n",
    "print(f\"State Space: {state_space}\")\n",
    "print(f\"Action Space Size: {action_space_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test DRL Agents\n",
    "Train and test at least two different DRL agents using the algorithms provided in Stable Baselines3 with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent: 255.0 +/- 0.0\n",
      "Mean reward for DQN agent: 84.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.Tanh, net_arch=[64, 64])\n",
    "\n",
    "# Create a log directory\n",
    "log_dir = './logs/'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.Tanh, net_arch=[64, 64])\n",
    "\n",
    "# Training the PPO agent\n",
    "ppo_model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'ppo_small/')\n",
    "ppo_model.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Training the DQN agent\n",
    "dqn_model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=VERBOSE,\n",
    "    tensorboard_log=log_dir + \"dqn_small/\",\n",
    ")\n",
    "dqn_model.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agent\n",
    "mean_reward_ppo, std_reward_ppo = evaluate_policy(ppo_model, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for PPO agent: {mean_reward_ppo} +/- {std_reward_ppo}\")\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward_dqn, std_reward_dqn = evaluate_policy(dqn_model, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for DQN agent: {mean_reward_dqn} +/- {std_reward_dqn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Different Neural Network Architectures\n",
    "Experiment with different neural network architectures for the DRL agents with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent: 720.0 +/- 0.0\n",
      "Mean reward for DQN agent: 577.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[128, 128])\n",
    "\n",
    "# Training the PPO agent\n",
    "ppo_model_large = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'ppo_large/')\n",
    "ppo_model_large.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Training the DQN agent\n",
    "dqn_model_large = DQN(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'dqn_large/')\n",
    "dqn_model_large.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agentP\n",
    "mean_reward, std_reward = evaluate_policy(ppo_model_large, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "print(f\"Mean reward for PPO agent: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward, std_reward = evaluate_policy(dqn_model_large, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "print(f\"Mean reward for DQN agent: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the Algorithms Hyperparameters\n",
    "Tune the hyperparameters of the algorithms by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent after hyperparameter tuning: 577.0 +/- 0.0\n",
      "Mean reward for DQN agent after hyperparameter tuning: 577.0 +/- 0.0\n",
      "Mean reward for A2C agent after hyperparameter tuning: 577.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[128, 128])\n",
    "\n",
    "# Tuning the hyperparameters of the PPO agent\n",
    "ppo_model_tuned = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, learning_rate=0.0003, n_steps=2048,\n",
    "                      batch_size=64, n_epochs=10, gamma=0.99, gae_lambda=0.95, clip_range=0.2, tensorboard_log=log_dir + 'ppo_tuned/')\n",
    "ppo_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agent\n",
    "mean_reward_ppo, std_reward_ppo = evaluate_policy(ppo_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for PPO agent after hyperparameter tuning: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# Tuning the hyperparameters of the DQN agent\n",
    "dqn_model_tuned = DQN(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, learning_rate=0.0005, buffer_size=10000, learning_starts=1000,\n",
    "                      batch_size=64, exploration_initial_eps=0.99, exploration_final_eps=0.02 , tau=1.0, gamma=0.99, train_freq=4, gradient_steps=1, tensorboard_log=log_dir + 'dqn_tuned/')\n",
    "dqn_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward_dqn, std_reward_dqn = evaluate_policy(dqn_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for DQN agent after hyperparameter tuning: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# Tuning the hyperparameters of the A2C agent\n",
    "a2c_model_tuned = A2C(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, learning_rate=0.0007, n_steps=5,\n",
    "                      gamma=0.99, gae_lambda=1.0, ent_coef=0.0, vf_coef=0.5, max_grad_norm=0.5, use_rms_prop=False, use_sde=False, tensorboard_log=log_dir + 'a2c_tuned/')\n",
    "a2c_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the A2C agent\n",
    "mean_reward_a2c, std_reward_a2c = evaluate_policy(a2c_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for A2C agent after hyperparameter tuning: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Agents and Compare Results\n",
    "Evaluate the performance of the agents and compare the best results obtained using the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the agents and their corresponding mean rewards and standard deviations\n",
    "agents = ['PPO', 'DQN', 'A2C']\n",
    "mean_rewards = [mean_reward_ppo, mean_reward_dqn, mean_reward_a2c]\n",
    "std_rewards = [std_reward_ppo, std_reward_dqn, std_reward_a2c]\n",
    "\n",
    "# Plotting the mean rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(agents, mean_rewards, yerr=std_rewards, align='center', alpha=0.7, ecolor='black', capsize=10)\n",
    "plt.ylabel('Mean Reward')\n",
    "plt.title('Comparison of Mean Rewards of Different Agents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is DQN with a mean reward of 641.0\n"
     ]
    }
   ],
   "source": [
    "# Define the agents and their corresponding mean rewards, standard deviations, and models\n",
    "agents = ['PPO', 'DQN', 'A2C']\n",
    "mean_rewards = [mean_reward_ppo, mean_reward_dqn, mean_reward_a2c]\n",
    "models = [ppo_model_tuned, dqn_model_tuned, a2c_model_tuned]\n",
    "\n",
    "# Save all the 3 tuned models using list comprehension\n",
    "[model.save(name) for model, name in zip(models, [\"models/ppo_tuned\", \"models/dqn_tuned\", \"models/a2c_tuned\"])]\n",
    "\n",
    "# Determine the index of the best model\n",
    "best_index = np.argmax(mean_rewards)\n",
    "\n",
    "print(f\"The best model is {agents[best_index]} with a mean reward of {mean_rewards[best_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2\n",
    "\n",
    "---\n",
    "\n",
    "## Enabling action masking, train and test a MaskablePPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 3111.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a function for the mask\n",
    "def mask_fn(env):\n",
    "    return env.get_mask()\n",
    "\n",
    "# Create an instance of the environment with mask enabled\n",
    "env = BoundedKnapsackEnv(n_items=200, max_weight=200, mask=True)\n",
    "\n",
    "# Wrap the environment with the ActionMasker\n",
    "vec_env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Create an evaluation environment\n",
    "eval_vec_env = Monitor(vec_env)\n",
    "\n",
    "# Define the policy architecture\n",
    "policy_kwargs = dict(\n",
    "    net_arch=dict(pi=[128, 128, 128], vf=[128, 128, 128]),  \n",
    ")\n",
    "\n",
    "# Train a MaskablePPO agent\n",
    "model = MaskablePPO(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=VERBOSE,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    learning_rate=3e-4,\n",
    "    tensorboard_log=log_dir + 'maskable_ppo/'\n",
    ")\n",
    "\n",
    "# Adjust timesteps for meaningful training\n",
    "model.learn(total_timesteps=TIME_STEPS, use_masking=True)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy_maskable(model, eval_vec_env, n_eval_episodes=EVAL_EPISODES, use_masking=True)\n",
    "\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with different neural network architectures and tune the algorithm hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\sb3_contrib\\common\\maskable\\policies.py:78: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: [{'pi': [64, 64], 'vf': [64, 64]}], Learning Rate: 0.0003, Mean reward: 3111.0 +/- 0.0\n",
      "New best mean reward: 3472.0 +/- 0.0, model saved.\n",
      "Architecture: [{'pi': [256, 256], 'vf': [256, 256]}], Learning Rate: 0.001, Mean reward: 3111.0 +/- 0.0\n",
      "Architecture: [{'pi': [128, 128], 'vf': [128, 128]}], Learning Rate: 0.0001, Mean reward: 3111.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a list of configurations to experiment with\n",
    "configurations = [\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[64, 64], vf=[64, 64])),\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"n_steps\": 2048,\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"gamma\": 0.99,\n",
    "    },\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[256, 256], vf=[256, 256])),\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"n_steps\": 1024,\n",
    "        \"ent_coef\": 0.01,\n",
    "        \"gamma\": 0.97,\n",
    "    },\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[128, 128], vf=[128, 128])),\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"n_steps\": 4096,\n",
    "        \"ent_coef\": 0.02,\n",
    "        \"gamma\": 0.95,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Initialize best mean reward to negative infinity\n",
    "best_mean_reward = -np.inf\n",
    "\n",
    "# Loop over the architectures and learning rates\n",
    "for config in configurations:\n",
    "    policy_kwargs = config[\"policy_kwargs\"]\n",
    "    model = MaskablePPO(\n",
    "        \"MlpPolicy\",\n",
    "        vec_env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=VERBOSE,\n",
    "        n_steps=config[\"n_steps\"],\n",
    "        batch_size=64,\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        ent_coef=config[\"ent_coef\"],\n",
    "        gamma=config[\"gamma\"],\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        target_kl=None,\n",
    "        tensorboard_log=log_dir + 'maskable_ppo/',\n",
    "    )\n",
    "    model.learn(total_timesteps=TIME_STEPS, use_masking=True)\n",
    "    mean_reward_mppo, std_reward_mppo = evaluate_policy_maskable(model, eval_vec_env, n_eval_episodes=EVAL_EPISODES, use_masking=True)\n",
    "    print(f\"Architecture: {config['policy_kwargs']['net_arch']}, Learning Rate: {config['learning_rate']}, Mean reward: {mean_reward} +/- {std_reward}\")    \n",
    "    # If this mean reward is greater than the current best, save this model\n",
    "    if mean_reward_mppo > best_mean_reward:\n",
    "        best_mean_reward = mean_reward_mppo\n",
    "        model.save(\"models/mppo_best\")\n",
    "        print(f\"New best mean reward: {mean_reward_mppo} +/- {std_reward_mppo}, model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the agent and compare the best results obtained with those of the best agent from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 - Mean reward: 641.0 +/- 0.0\n",
      "Part 2 - Mean reward: 3472.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from Part 1\n",
    "if agents[best_index] == 'PPO':\n",
    "    best_model_part1 = PPO.load(\"models/ppo_tuned\", env=env)\n",
    "elif agents[best_index] == 'DQN':\n",
    "    best_model_part1 = DQN.load(\"models/dqn_tuned\", env=env)\n",
    "elif agents[best_index] == 'A2C':\n",
    "    best_model_part1 = A2C.load(\"models/a2c_tuned\", env=env)\n",
    "else:\n",
    "    print(\"Unknown model type\")\n",
    "\n",
    "# Load the best model from Part 2\n",
    "best_model_part2 = MaskablePPO.load(\"models/mppo_best\", env=env)\n",
    "\n",
    "# Evaluate the best model from Part 1\n",
    "mean_reward_part1, std_reward_part1 = evaluate_policy(best_model_part1, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "# Evaluate the best model from Part 2\n",
    "mean_reward_part2, std_reward_part2 = evaluate_policy_maskable(best_model_part2, eval_vec_env, n_eval_episodes=EVAL_EPISODES)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Part 1 - Mean reward: {mean_reward_part1} +/- {std_reward_part1}\")\n",
    "print(f\"Part 2 - Mean reward: {mean_reward_part2} +/- {std_reward_part2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
