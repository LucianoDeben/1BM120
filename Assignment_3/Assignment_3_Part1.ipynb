{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "Install the necessary libraries, including Gymnasium, Stable Baselines3, and SB3 Contrib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy as evaluate_policy_maskable\n",
    "\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Import BoundedKnapsack Environment\n",
    "from knapsack_env import BoundedKnapsackEnv\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "seed = 2024\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "TIME_STEPS = 10000\n",
    "EVAL_EPISODES = 100   \n",
    "EVAL_FREQ = int(TIME_STEPS**0.5)     \n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Instance of the Environment\n",
    "Create an instance of the BoundedKnapsack environment with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Space: (array([[ 82,  65,  60,  69,  35,  87,  35,  48,  40,  23,  15,  86,   3,\n",
      "         41,  26,  64,  42,  52,  95,  67,  17,  45,  93,  30,  53,  50,\n",
      "         20,  74,  49,  66,   5,  48,  51,  19,  71,  51,  10,  93,  44,\n",
      "         55,  28,  93,  31,  37,  88,  30,   6,   3,   9,   9,  37,  15,\n",
      "         38,  83,  39,  26,  33,  98,  69,  82,  25,  90,  18,  57,  95,\n",
      "         95,  60,  65,  38,  86,  57,  80,  75,  70,  10,  19,  20,  66,\n",
      "         57,  42,  36,  30,  63,  35,  22,  34,  59,  80,  48,  56,  70,\n",
      "         55,  20,  21,  83,  57,  43,  66,  71,  79,   3,  99,   7,  54,\n",
      "         58,  79,  69,  43,  40,   6,  34,  73,  15,  19,  32,  82,  31,\n",
      "          9,   2,  31,  54,  83,  68,  44,  59,  41,  63,  28,  95,  48,\n",
      "         36,  98,  91,  71,  39,  31,  60,  11,  33,  10,  94,  93,  30,\n",
      "         36,  34,  20,  99,  80,  85,  89,  49,  79,  85,  76,   3,  50,\n",
      "         63,  11,  83,  40,  23,  68,  29,  55,  43,  12,  28,  21,  52,\n",
      "         52,  44,  45,  46,  93,  24,  26,  26,  17,  59,  62,  98,  71,\n",
      "         30,  21,  76,  46,  80,   9,  69,  93,  95,  15,  68,  36,  86,\n",
      "         43,  66,  64,  66,  10, 200],\n",
      "       [ 89,  97,  29,  59,  83,  95,   2,   6,  33,  55,  75,  36,   5,\n",
      "          9,  75,  25,  40,  94,  71,  15,  21,  77,   7,  61,  81,  93,\n",
      "         85,  30,  47,  14,  85,  18,  27,  92,   8,  54,  63,  37,  67,\n",
      "         98,  37,  86,  30,   3,  50,  55,  80,  36,  74,  53,   3,  31,\n",
      "         28,  40,  64,  44,  41,  61,  96,  38,  75,  15,  21,  59,  16,\n",
      "         94,  94,  34,  86,  30,  79,  78,  45,  97,  88,  70,  19,  36,\n",
      "          5,  24,  42,  52,  64,  63,  85,  11,  72,  73,  10,  82,  15,\n",
      "          0,  90,  73,  21,   4,  24,  96,  23,  86,  38,   6,  69,  43,\n",
      "         44,  43,  49,  57,  98,  79,  54,  78,  57,   2,  83,  93,  76,\n",
      "         27,  85,  26,  92,  52,  28,  58,  76,  31,  66,  66,  83,  83,\n",
      "         54,  44,  72,  72,  76,  48,  42,  53,  84,  58,  23,  45,  17,\n",
      "         37,   5,  58,  19,  92,  86,  90,  23,  73,   9,  13,   0,  79,\n",
      "         61,  62,  91,  24,  14,  97,  81,  94,  73,  54,  54,   4,  86,\n",
      "         80,  71,  60,  90,  62,  51,  96,  49,  63,  87,  90,  90,  17,\n",
      "          8,  28,  69,   9,  72,  31,  72,  34,   6,  52,  49,  50,  42,\n",
      "         35,  82,  40,   5,   8,   0],\n",
      "       [  5,   8,   3,   5,   3,   6,   6,   1,   9,   9,   2,   9,   8,\n",
      "          2,   5,   9,   1,   3,   3,   4,   4,   1,   4,   2,   7,   7,\n",
      "          5,   2,   9,   3,   4,   2,   4,   6,   2,   8,   5,   3,   3,\n",
      "          1,   3,   4,   1,   9,   4,   3,   3,   5,   5,   4,   3,   9,\n",
      "          9,   5,   3,   7,   7,   7,   2,   3,   9,   1,   3,   5,   8,\n",
      "          5,   1,   8,   6,   8,   5,   1,   4,   4,   1,   5,   5,   5,\n",
      "          3,   1,   7,   9,   8,   4,   7,   5,   6,   3,   2,   1,   3,\n",
      "          3,   8,   2,   9,   6,   2,   6,   1,   9,   4,   5,   1,   4,\n",
      "          4,   1,   2,   8,   1,   5,   9,   3,   5,   2,   1,   2,   2,\n",
      "          9,   3,   6,   1,   1,   3,   8,   1,   8,   5,   3,   5,   7,\n",
      "          1,   6,   3,   2,   3,   8,   5,   9,   7,   1,   6,   6,   6,\n",
      "          3,   3,   4,   4,   8,   2,   3,   4,   6,   3,   3,   8,   1,\n",
      "          5,   3,   6,   6,   6,   5,   2,   4,   5,   9,   5,   8,   2,\n",
      "          6,   6,   8,   8,   7,   9,   6,   4,   4,   5,   4,   2,   7,\n",
      "          9,   8,   3,   8,   8,   6,   3,   4,   9,   4,   9,   1,   6,\n",
      "          3,   1,   8,   9,   7,   0]]), {})\n",
      "Action Space Size: 200\n"
     ]
    }
   ],
   "source": [
    "# Enable the environment\n",
    "env = BoundedKnapsackEnv(n_items=200, max_weight=200)\n",
    "\n",
    "# Create evaluation environment\n",
    "eval_env = Monitor(env)\n",
    "\n",
    "# Inspect the state space and action spaces\n",
    "state_space = env.reset()\n",
    "action_space_size = env.action_space.n\n",
    "\n",
    "# Print the state space and action space size\n",
    "print(f\"State Space: {state_space}\")\n",
    "print(f\"Action Space Size: {action_space_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test DRL Agents\n",
    "Train and test at least two different DRL agents using the algorithms provided in Stable Baselines3 with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent: 255.0 +/- 0.0\n",
      "Mean reward for DQN agent: 183.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.Tanh, net_arch=[64, 64])\n",
    "\n",
    "# Create a log directory\n",
    "log_dir = './logs/'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.Tanh, net_arch=[64, 64])\n",
    "\n",
    "# Training the PPO agent\n",
    "ppo_model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'ppo_small/')\n",
    "ppo_model.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Training the DQN agent\n",
    "dqn_model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=VERBOSE,\n",
    "    tensorboard_log=log_dir + \"dqn_small/\",\n",
    ")\n",
    "dqn_model.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agent\n",
    "mean_reward_ppo, std_reward_ppo = evaluate_policy(ppo_model, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for PPO agent: {mean_reward_ppo} +/- {std_reward_ppo}\")\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward_dqn, std_reward_dqn = evaluate_policy(dqn_model, eval_env, n_eval_episodes=EVAL_EPISODES)\n",
    "print(f\"Mean reward for DQN agent: {mean_reward_dqn} +/- {std_reward_dqn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Different Neural Network Architectures\n",
    "Experiment with different neural network architectures for the DRL agents with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent: 855.0 +/- 0.0\n",
      "Mean reward for DQN agent: 386.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[128, 128])\n",
    "\n",
    "# Training the PPO agent\n",
    "ppo_model_large = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'ppo_large/')\n",
    "ppo_model_large.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Training the DQN agent\n",
    "dqn_model_large = DQN(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, tensorboard_log=log_dir + 'dqn_large/')\n",
    "dqn_model_large.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agentP\n",
    "mean_reward, std_reward = evaluate_policy(ppo_model_large, eval_env, n_eval_episodes=EVAL_EPISODES, deterministic=False)\n",
    "\n",
    "print(f\"Mean reward for PPO agent: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward, std_reward = evaluate_policy(dqn_model_large, eval_env, n_eval_episodes=EVAL_EPISODES, deterministic=False)\n",
    "\n",
    "print(f\"Mean reward for DQN agent: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the Algorithms Hyperparameters\n",
    "Tune the hyperparameters of the algorithms by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for PPO agent after hyperparameter tuning: 98.0 +/- 0.0\n",
      "Mean reward for DQN agent after hyperparameter tuning: 138.0 +/- 0.0\n",
      "Mean reward for A2C agent after hyperparameter tuning: 182.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[128, 128])\n",
    "\n",
    "# Tuning the hyperparameters of the PPO agent\n",
    "ppo_model_tuned = PPO(\n",
    "    \"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, \n",
    "    learning_rate=0.0003, n_steps=2048, batch_size=64, n_epochs=10, \n",
    "    gamma=0.99, gae_lambda=0.95, clip_range=0.2, ent_coef=0.01, \n",
    "    tensorboard_log=log_dir + 'ppo_tuned/'\n",
    ")\n",
    "ppo_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the PPO agent\n",
    "mean_reward_ppo, std_reward_ppo = evaluate_policy(ppo_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES, deterministic=False)\n",
    "print(f\"Mean reward for PPO agent after hyperparameter tuning: {mean_reward_ppo} +/- {std_reward_ppo}\")\n",
    "\n",
    "# Tuning the hyperparameters of the DQN agent\n",
    "dqn_model_tuned = DQN(\n",
    "    \"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, \n",
    "    learning_rate=0.0001, buffer_size=1000000, learning_starts=50000, \n",
    "    batch_size=32, exploration_initial_eps=1.0, exploration_final_eps=0.1, \n",
    "    exploration_fraction=0.1, train_freq=4, gamma=0.99, \n",
    "    target_update_interval=10000, tensorboard_log=log_dir + 'dqn_tuned/'\n",
    ")\n",
    "dqn_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the DQN agent\n",
    "mean_reward_dqn, std_reward_dqn = evaluate_policy(dqn_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES, deterministic=False)\n",
    "print(f\"Mean reward for DQN agent after hyperparameter tuning: {mean_reward_dqn} +/- {std_reward_dqn}\")\n",
    "\n",
    "# Tuning the hyperparameters of the A2C agent\n",
    "a2c_model_tuned = A2C(\n",
    "    \"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=VERBOSE, \n",
    "    learning_rate=0.0007, n_steps=5, gamma=0.99, gae_lambda=1.0, \n",
    "    ent_coef=0.01, vf_coef=0.5, max_grad_norm=0.5, \n",
    "    tensorboard_log=log_dir + 'a2c_tuned/'\n",
    ")\n",
    "a2c_model_tuned.learn(total_timesteps=TIME_STEPS)\n",
    "\n",
    "# Evaluating the A2C agent\n",
    "mean_reward_a2c, std_reward_a2c = evaluate_policy(a2c_model_tuned, eval_env, n_eval_episodes=EVAL_EPISODES, deterministic=False)\n",
    "print(f\"Mean reward for A2C agent after hyperparameter tuning: {mean_reward_a2c} +/- {std_reward_a2c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Agents and Compare Results\n",
    "Evaluate the performance of the agents and compare the best results obtained using the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the agents and their corresponding mean rewards and standard deviations\n",
    "agents = ['PPO', 'DQN', 'A2C']\n",
    "mean_rewards = [mean_reward_ppo, mean_reward_dqn, mean_reward_a2c]\n",
    "std_rewards = [std_reward_ppo, std_reward_dqn, std_reward_a2c]\n",
    "\n",
    "# Plotting the mean rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(agents, mean_rewards, yerr=std_rewards, align='center', alpha=0.7, ecolor='black', capsize=10)\n",
    "plt.ylabel('Mean Reward')\n",
    "plt.title('Comparison of Mean Rewards of Different Agents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is A2C with a mean reward of 182.0\n"
     ]
    }
   ],
   "source": [
    "# Define the agents and their corresponding mean rewards, standard deviations, and models\n",
    "agents = ['PPO', 'DQN', 'A2C']\n",
    "mean_rewards = [mean_reward_ppo, mean_reward_dqn, mean_reward_a2c]\n",
    "models = [ppo_model_tuned, dqn_model_tuned, a2c_model_tuned]\n",
    "\n",
    "# Save all the 3 tuned models using list comprehension\n",
    "[model.save(name) for model, name in zip(models, [\"models/ppo_tuned\", \"models/dqn_tuned\", \"models/a2c_tuned\"])]\n",
    "\n",
    "# Determine the index of the best model\n",
    "best_index = np.argmax(mean_rewards)\n",
    "\n",
    "print(f\"The best model is {agents[best_index]} with a mean reward of {mean_rewards[best_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2\n",
    "\n",
    "---\n",
    "\n",
    "## Enabling action masking, train and test a MaskablePPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 2207.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a function for the mask\n",
    "def mask_fn(env):\n",
    "    return env.get_mask()\n",
    "\n",
    "# Create an instance of the environment with mask enabled\n",
    "env = BoundedKnapsackEnv(n_items=200, max_weight=200, mask=True)\n",
    "\n",
    "# Wrap the environment with the ActionMasker\n",
    "vec_env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Create an evaluation environment\n",
    "eval_vec_env = Monitor(vec_env)\n",
    "\n",
    "# Define the policy architecture\n",
    "policy_kwargs = dict(\n",
    "    net_arch=dict(pi=[128, 128, 128], vf=[128, 128, 128]),  \n",
    ")\n",
    "\n",
    "# Train a MaskablePPO agent\n",
    "model = MaskablePPO(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=VERBOSE,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    learning_rate=3e-4,\n",
    "    tensorboard_log=log_dir + 'maskable_ppo/'\n",
    ")\n",
    "\n",
    "# Adjust timesteps for meaningful training\n",
    "model.learn(total_timesteps=TIME_STEPS, use_masking=True)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy_maskable(model, eval_vec_env, n_eval_episodes=EVAL_EPISODES, use_masking=True, deterministic=False)\n",
    "\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with different neural network architectures and tune the algorithm hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: {'pi': [64, 64], 'vf': [64, 64]}, Learning Rate: 0.0003, Mean reward: 2207.0 +/- 0.0\n",
      "New best mean reward: 2623.0 +/- 0.0, model saved.\n",
      "Architecture: {'pi': [256, 256], 'vf': [256, 256]}, Learning Rate: 0.001, Mean reward: 2207.0 +/- 0.0\n",
      "New best mean reward: 3237.0 +/- 0.0, model saved.\n",
      "Architecture: {'pi': [128, 128], 'vf': [128, 128]}, Learning Rate: 0.0001, Mean reward: 2207.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a list of configurations to experiment with\n",
    "configurations = [\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[64, 64], vf=[64, 64])),\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"n_steps\": 2048,\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"gamma\": 0.99,\n",
    "    },\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[256, 256], vf=[256, 256])),\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"n_steps\": 1024,\n",
    "        \"ent_coef\": 0.01,\n",
    "        \"gamma\": 0.97,\n",
    "    },\n",
    "    {\n",
    "        \"policy_kwargs\": dict(net_arch=dict(pi=[128, 128], vf=[128, 128])),\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"n_steps\": 4096,\n",
    "        \"ent_coef\": 0.02,\n",
    "        \"gamma\": 0.95,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Initialize best mean reward to negative infinity\n",
    "best_mean_reward = -np.inf\n",
    "\n",
    "# Loop over the architectures and learning rates\n",
    "for config in configurations:\n",
    "    policy_kwargs = config[\"policy_kwargs\"]\n",
    "    model = MaskablePPO(\n",
    "        \"MlpPolicy\",\n",
    "        vec_env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=VERBOSE,\n",
    "        n_steps=config[\"n_steps\"],\n",
    "        batch_size=64,\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        ent_coef=config[\"ent_coef\"],\n",
    "        gamma=config[\"gamma\"],\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        target_kl=None,\n",
    "        tensorboard_log=log_dir + 'maskable_ppo/',\n",
    "    )\n",
    "    model.learn(total_timesteps=TIME_STEPS, use_masking=True)\n",
    "    mean_reward_mppo, std_reward_mppo = evaluate_policy_maskable(model, eval_vec_env, n_eval_episodes=EVAL_EPISODES, use_masking=True, deterministic=False)\n",
    "    print(f\"Architecture: {config['policy_kwargs']['net_arch']}, Learning Rate: {config['learning_rate']}, Mean reward: {mean_reward} +/- {std_reward}\")    \n",
    "    # If this mean reward is greater than the current best, save this model\n",
    "    if mean_reward_mppo > best_mean_reward:\n",
    "        best_mean_reward = mean_reward_mppo\n",
    "        model.save(\"models/mppo_best\")\n",
    "        print(f\"New best mean reward: {mean_reward_mppo} +/- {std_reward_mppo}, model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the agent and compare the best results obtained with those of the best agent from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 - Mean reward: 182.0 +/- 0.0\n",
      "Part 2 - Mean reward: 3237.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from Part 1\n",
    "if agents[best_index] == 'PPO':\n",
    "    best_model_part1 = PPO.load(\"models/ppo_tuned\", env=env)\n",
    "elif agents[best_index] == 'DQN':\n",
    "    best_model_part1 = DQN.load(\"models/dqn_tuned\", env=env)\n",
    "elif agents[best_index] == 'A2C':\n",
    "    best_model_part1 = A2C.load(\"models/a2c_tuned\", env=env)\n",
    "else:\n",
    "    print(\"Unknown model type\")\n",
    "\n",
    "# Load the best model from Part 2\n",
    "best_model_part2 = MaskablePPO.load(\"models/mppo_best\", env=env)\n",
    "\n",
    "# Evaluate the best model from Part 1\n",
    "mean_reward_part1, std_reward_part1 = evaluate_policy(best_model_part1, eval_env, n_eval_episodes=EVAL_EPISODES, deterministic=False)\n",
    "\n",
    "# Evaluate the best model from Part 2\n",
    "mean_reward_part2, std_reward_part2 = evaluate_policy_maskable(best_model_part2, eval_vec_env, n_eval_episodes=EVAL_EPISODES, deterministic=False, use_masking=True)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Part 1 - Mean reward: {mean_reward_part1} +/- {std_reward_part1}\")\n",
    "print(f\"Part 2 - Mean reward: {mean_reward_part2} +/- {std_reward_part2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
