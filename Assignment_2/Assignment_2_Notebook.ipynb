{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Convolutional Neural Networks and AutoML\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "Import the necessary libraries, including PyTorch and the chosen hyperparameter optimization library. Also import local modules and set global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from support import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from model import SimpleCNN\n",
    "from train_test_optimize import train_model, test_model, objective_with_cv\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global parameters\n",
    "EPOCHS = 2\n",
    "N_TRIALS = 2\n",
    "MODEL = SimpleCNN\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess the Wefabricate Dataset\n",
    "Load the Wefabricate dataset and preprocess it for use with a CNN. Preprocessing is handles by the `load_dataset` function from `support.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset()\n",
    "\n",
    "print(f\"Train data: {len(train_data)}\")\n",
    "print(f\"Test data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data with their labels\n",
    "Check a few samples from the train loader to see wheter the labels match the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels \n",
    "class_labels = [\"Defect\", \"No Defect\"]\n",
    "\n",
    "# Get a batch of training data\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Create a grid of the images and print the labels\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(images[i][0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(class_labels[labels[i]])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the CNN Model\n",
    "Define a CNN to classify product images in the Wefabricate dataset. The `SimpleCNN` model class is defined in `model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the network\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN Model\n",
    "Train the CNN model on the training set. First define the loss and optimizer functions and ensure model is on DEVICE (GPU, if available). The `train_model` function is defined in `train_test_optimize`, which saves models with the `model_name` prefix to the `models/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_losses = train_model(model, train_data, criterion, optimizer, DEVICE, n_epochs=EPOCHS, model_name=\"initial_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training and validation loss over epochs\n",
    "Visualizing the train and validation loss allows for identifying potential problems the learning rate or model complexity. Additionally, overfitting can be identified when the validation loss divergences from the training loss after certain epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training loss over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training and Validation Loss per Epoch\")\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the CNN Model\n",
    "Test the trained CNN model on the test set and calculate performace metrics. The `test_model` function is defined in the `train_test_optimize.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on the test data and get metrics\n",
    "accuracy, precision, recall, f1 = test_model(model, test_data, DEVICE)\n",
    "\n",
    "# Visualize the metrics in a table\n",
    "metrics = pd.DataFrame({\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1': [f1]\n",
    "})\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Selection\n",
    "First hyperparameters of interest are described after which both random search and Tree-structured Parzen Estimator (TPE) search HPO is performed with a 5-fold cross-validation scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Learning Rate\n",
    "\n",
    "**Importance:**  \n",
    "The learning rate is fundamental as it determines how much to update the model's weights based on the error each time the model weights are updated. If set too high, the model might overshoot the minimum, leading to erratic behaviors. If too low, the model could take too long to converge or might get stuck in a local minimum.\n",
    "\n",
    "**Relevance to Wefabricate:**  \n",
    "Given that we are dealing with a small dataset (136 training images), an optimal learning rate is crucial to ensure efficient convergence without overshooting, as CNNs are sensitive to this parameter in such scenarios.\n",
    "\n",
    "#### 2) Batch Size\n",
    "\n",
    "**Importance:**  \n",
    "The batch size affects the stability of the training process. Larger batch sizes result in smoother (less noisy) gradient estimates, but are computationally more demanding and can lead to poorer generalization. Smaller batches can offer a regularizing effect and lower generalization error.\n",
    "\n",
    "**Relevance to Wefabricate:**  \n",
    "Adjusting the batch size can help balance between computation efficiency and model performance, especially when resources are limited or when the dataset is small, as is the case in the Wefabricate dataset.\n",
    "\n",
    "#### 3) Dropout rate\n",
    "\n",
    "**Importance:**\n",
    "This parameter controls the fraction of neurons that are randomly dropped out during training to prevent overfitting. A higher dropout rate means more neurons are ignored during each forward and backward pass, which helps in regularizing the model and improving its generalization capabilities. However, if the dropout rate is too high, the model might underfit, failing to learn important patterns in the data.\n",
    "\n",
    "**Relevance to Wefabricate:**\n",
    "Optimal dropout rate setting ensures that the model remains robust and generalizes well to new, unseen images by preventing it from memorizing the noise in the training data. This is particularly important given the limited data available, as it helps the model learn meaningful patterns without overfitting.\n",
    "\n",
    "#### 4) Weight Decay\n",
    "\n",
    "**Importance:**  \n",
    "Weight decay (L2 regularization) helps prevent overfitting by penalizing large weights. This regularization method encourages simpler models that may generalize better on unseen data.\n",
    "\n",
    "**Relevance to Wefabricate:**  \n",
    "With a relatively small dataset and a potentially complex model, weight decay can help maintain the balance between bias and variance, thus improving the model's general performance on new, unseen images.\n",
    "\n",
    "#### 5) Optimizer\n",
    "\n",
    "**Importance:**  \n",
    "The choice of optimizer can significantly affect the training speed and quality of the final model. Different optimizers can manage different types of data and architectures more effectively, with some being better at handling noisy gradients or avoiding local minima.\n",
    "\n",
    "**Relevance to Wefabricate:**  \n",
    "Given the task's sensitivity to hyperparameter settings due to the small data size, choosing the right optimizer (like Adam, which is generally robust, or SGD, which might benefit from fine-grained control over learning momentum) can lead to better or faster convergence in training the CNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross-Validation Hyperparameter Optimization with Optuna\n",
    "Perform 5-fold cross-validation on the training set to calculate the validation accuracy for the hyperparameters. The optimal hyperparameters are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the objective function with partial\n",
    "objective = partial(objective_with_cv, n_epochs=EPOCHS, model_class=MODEL, train_data=train_data, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search with Optuna\n",
    "study_random = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())\n",
    "study_random.optimize(objective, n_trials=N_TRIALS)\n",
    "best_params_random = study_random.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPE search with Optuna\n",
    "study_tpe = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())\n",
    "study_tpe.optimize(objective, n_trials=N_TRIALS)\n",
    "best_params_tpe = study_tpe.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Results Before and After Hyperparameter Optimization\n",
    "Compare the results obtained before and after automatic hyperparameter optimization in terms of accuracy, for the default model, the random search HPO model and the TPE search HPO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before optimization\n",
    "default_model = SimpleCNN().to(DEVICE)\n",
    "default_optimizer = optim.Adam(default_model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "default_train_losses, default_val_losses = train_model(default_model, train_data, criterion, default_optimizer, DEVICE, n_epochs=EPOCHS, model_name=\"default_model\")\n",
    "default_accuracy, default_precision, default_recall, default_f1 = test_model(default_model, test_data, DEVICE)\n",
    "\n",
    "# After optimization (Random search)\n",
    "optimized_model_random = SimpleCNN(dropout_rate=best_params_random['dropout_rate']).to(DEVICE)\n",
    "optimized_optimizer_random = getattr(optim, best_params_random['optimizer'])(optimized_model_random.parameters(), lr=best_params_random['learning_rate'], weight_decay=best_params_random['weight_decay'])\n",
    "optimized_train_losses_random, optimized_val_losses_random = train_model(optimized_model_random, train_data, criterion, optimized_optimizer_random, DEVICE, n_epochs=EPOCHS, model_name=\"optimized_model_random\")\n",
    "optimized_accuracy_random, optimized_precision_random, optimized_recall_random, optimized_f1_random = test_model(optimized_model_random, test_data, DEVICE)\n",
    "\n",
    "# After optimization (TPE search)\n",
    "optimized_model_tpe = SimpleCNN(dropout_rate=best_params_tpe['dropout_rate']).to(DEVICE)\n",
    "optimized_optimizer_tpe = getattr(optim, best_params_tpe['optimizer'])(optimized_model_tpe.parameters(), lr=best_params_tpe['learning_rate'], weight_decay=best_params_tpe['weight_decay'])\n",
    "optimized_train_losses_tpe, optimized_val_losses_tpe = train_model(optimized_model_tpe, train_data, criterion, optimized_optimizer_tpe, DEVICE, n_epochs=EPOCHS, model_name=\"optimized_model_tpe\")\n",
    "optimized_accuracy_tpe, optimized_precision_tpe, optimized_recall_tpe, optimized_f1_tpe = test_model(optimized_model_tpe, test_data, DEVICE)\n",
    "\n",
    "# Create a DataFrame to visualize the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Default', 'Optimized (Random search)', 'Optimized (TPE search)'],\n",
    "    'Accuracy': [default_accuracy, optimized_accuracy_random, optimized_accuracy_tpe],\n",
    "    'Precision': [default_precision, optimized_precision_random, optimized_precision_tpe],\n",
    "    'Recall': [default_recall, optimized_recall_random, optimized_recall_tpe],\n",
    "    'F1 Score': [default_f1, optimized_f1_random, optimized_f1_tpe]\n",
    "})\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "# Optionally, to display as a formatted table\n",
    "print(metrics_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the validation losses of the 3 different models\n",
    "Visualizing the validation losses can help in identifying problems during training and compare the model performances over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation losses for each model\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot validation losses for the default model\n",
    "plt.plot(default_val_losses, label='Default Model', linestyle='-', marker='o')\n",
    "\n",
    "# Plot validation losses for the random search optimized model\n",
    "plt.plot(optimized_val_losses_random, label='Random Search Optimized Model', linestyle='-', marker='x')\n",
    "\n",
    "# Plot validation losses for the TPE search optimized model\n",
    "plt.plot(optimized_val_losses_tpe, label='TPE Search Optimized Model', linestyle='-', marker='s')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Validation Losses per Epoch for Different Models')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1BM120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
